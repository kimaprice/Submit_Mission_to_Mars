{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "491ce5e1",
   "metadata": {},
   "source": [
    "# Mission to Mars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c84edb",
   "metadata": {},
   "source": [
    "### Part 1: Scraping the information from\n",
    "\n",
    "* Mars New Site: https://redplanetscience.com/\n",
    "* Mars Images site: https://spaceimages-mars.com/\n",
    "* Mars Facts page: https://galaxyfacts-mars.com/\n",
    "* Mars Hemispheres images: https://marshemispheres.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912aaab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bfd6e7",
   "metadata": {},
   "source": [
    "#### 1a: Mars New Site: https://redplanetscience.com/\n",
    "* Get the latest article title\n",
    "* Get the latest article description paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b1e550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|█████████████████| 8.15M/8.15M [00:00<00:00, 19.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "#Open the browswer window - set up splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d2389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set URL to scrape\n",
    "url = 'https://redplanetscience.com/'\n",
    "\n",
    "# open the page in browswer\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64487cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e78731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locate the section containing the news articles\n",
    "container = soup.find('section', class_='image_and_description_container')\n",
    "\n",
    "#Locate the title and descriptive paragraph for the first article and save to variables\n",
    "news = container.find('div', class_='content_title').text\n",
    "news_p = container.find('div', class_='article_teaser_body').text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eb8ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72e76f7",
   "metadata": {},
   "source": [
    "#### 1b: Mars Images site: https://spaceimages-mars.com/\n",
    "* Get the URL for the featured Mars image (full sized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e790ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the browswer window - set up splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92fe3415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set URL to scrape\n",
    "url = 'https://spaceimages-mars.com/'\n",
    "\n",
    "# open the page in browswer\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9136a094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "720b810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = soup.find('div', class_ = \"floating_text_area\").a['href']\n",
    "featured_image_url = f'{url}{image}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2b0a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412a26c7",
   "metadata": {},
   "source": [
    "#### 1c: Mars Facts page: https://galaxyfacts-mars.com/\n",
    "* Get the table comtaining Mars facts (diamter, mass, etc)*\n",
    "* Use Pandas to convert to and HTML table string\n",
    "\n",
    "###### *Note: I selected the table with just Mars facts, not the one with earth and Mars since this project is on Mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57e69b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set url\n",
    "url = 'https://galaxyfacts-mars.com/'\n",
    "#use pandas to find all tables on the page\n",
    "tables = pd.read_html(url)\n",
    "#select the second table since it is in a side bar and there is one on the main page\n",
    "df = tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e405d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the dataframe into HTML\n",
    "html_table = df.to_html(classes = 'table table-stripped', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ca2870",
   "metadata": {},
   "source": [
    "####  1d: Mars Hemispheres images: https://marshemispheres.com/\n",
    "* Get the urls for each of the hemispheres (full resolution image)\n",
    "* store the hemisphere title and URL string to a list with one dictionary for each hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df8aa7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack Overflow URL to scrape\n",
    "url = 'https://marshemispheres.com/'\n",
    "# Retrieve page with the requests module\n",
    "response = requests.get(url)\n",
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#find section with the Hemisphere pages\n",
    "results = soup.find_all('div', class_='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e739111",
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls = []  \n",
    "    \n",
    "#for each Hemisphere\n",
    "for result in results:\n",
    "    #find the address for the hemisphere page and get hemi name\n",
    "    webadd = result.a['href']\n",
    "    hemi_name=result.find('h3').text\n",
    "       \n",
    "    #Open the browswer window - set up splinter\n",
    "    executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "    browser = Browser('chrome', **executable_path, headless=True)\n",
    "    \n",
    "    # set URL to scrape\n",
    "    hemi_url = url + webadd\n",
    "    \n",
    "    # open the page in browswer\n",
    "    browser.visit(hemi_url)\n",
    "    \n",
    "    # Create BeautifulSoup object; parse with 'html.parser'\n",
    "    hemi_html = browser.html\n",
    "    hemi_soup = BeautifulSoup(hemi_html, 'html.parser')\n",
    "\n",
    "    #find the url\n",
    "    hemi_image = hemi_soup.find('img', class_='wide-image')['src']\n",
    "    hemi_image_url = url+hemi_image\n",
    "     \n",
    "    # Dictionary to be inserted into list\n",
    "    hemi_dict = {\n",
    "        'title' : hemi_name,\n",
    "        'img_url' : hemi_image_url\n",
    "    }\n",
    "      \n",
    "    #Append dictionary to list\n",
    "    hemisphere_image_urls.append(hemi_dict)\n",
    "        \n",
    "    #Close Broswer\n",
    "    browser.quit()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964aa922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dict for listings that we can save to Mongo\n",
    "# Populate the dictionary with key-value pairs for Mars info and images\n",
    "\n",
    "MarsInfo = {}\n",
    "MarsInfo[\"NewsArtTitle\"] = news\n",
    "MarsInfo[\"NewsArtDesc\"] = news_p \n",
    "MarsInfo[\"FeatImage\"] = featured_image_url \n",
    "MarsInfo[\"FactTable\"] = html_table\n",
    "MarsInfo[\"HemiImages\"] = hemisphere_image_urls "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
